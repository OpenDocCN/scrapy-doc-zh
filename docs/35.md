# 部署 Spider

> 译者：[OSGeo 中国](https://www.osgeo.cn/)

本节描述了部署 Scrapy Spider 以定期运行它们的不同选项。在您的本地机器中运行碎片 Spider 对于（早期）开发阶段非常方便，但是当您需要执行长时间运行的 Spider 或移动 Spider 以在生产中连续运行时，就不那么方便了。这就是部署 Scrapy Spider 的解决方案。

部署 Scrapy Spider 的常见选择是：

*   [Scrapyd](#deploy-scrapyd) （开放源代码）
*   [Scrapy Cloud](#deploy-scrapy-cloud) （基于云的）

## 部署到ScrapyD服务器

[Scrapyd](https://github.com/scrapy/scrapyd) 是一个开放源码的应用程序，可以运行碎片 Spider 。它为服务器提供了HTTP API，能够运行和监视碎片 Spider 。

要将spiders部署到scrapyD，可以使用由提供的scrapyD部署工具 [scrapyd-client](https://github.com/scrapy/scrapyd-client) 包。请参阅 [scrapyd-deploy documentation](https://scrapyd.readthedocs.io/en/latest/deploy.html) 更多信息。

ScrapyD由一些Scrapy开发人员维护。

## 部署到碎片云

[Scrapy Cloud](https://scrapinghub.com/scrapy-cloud) 是基于云的托管服务 [Scrapinghub](https://scrapinghub.com/) 斯普利背后的公司。

ScrapyCloud消除了设置和监视服务器的需要，并提供了一个很好的用户界面来管理spider和查看被刮走的项目、日志和统计信息。

要将 Spider 部署到碎片云，可以使用 [shub](https://doc.scrapinghub.com/shub.html) 命令行工具。请参阅 [Scrapy Cloud documentation](https://doc.scrapinghub.com/scrapy-cloud.html) 更多信息。

Scrapy Cloud与ScrapyD兼容，您可以根据需要在它们之间进行切换-配置从 `scrapy.cfg` 文件就像 `scrapyd-deploy` .