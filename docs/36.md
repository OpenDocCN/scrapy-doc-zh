# AutoThrottle 扩展

> 译者：[OSGeo 中国](https://www.osgeo.cn/)

这是一个扩展，基于Scrapy服务器和您正在爬行的网站的负载，自动限制爬行速度。

## 设计目标

1.  对站点更好，而不是使用默认的下载延迟为零
2.  自动调整碎片到最佳的爬行速度，这样用户就不必调整下载延迟来找到最佳的。用户只需要指定它允许的最大并发请求，扩展就可以完成其余的工作。

## 它是如何工作的

AutoThrottle 扩展动态调整下载延迟，使 Spider 发送 [`AUTOTHROTTLE_TARGET_CONCURRENCY`](#std:setting-AUTOTHROTTLE_TARGET_CONCURRENCY) 平均每个远程网站的并发请求。

它使用下载延迟来计算延迟。主要思想如下：如果服务器需要 `latency` 响应时间为秒，客户端应每秒钟发送一个请求 `latency/N` 秒有 `N` 并行处理的请求。

不需要调整延迟，只需设置一个小的固定下载延迟，并对使用 [`CONCURRENT_REQUESTS_PER_DOMAIN`](settings.html#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN) 或 [`CONCURRENT_REQUESTS_PER_IP`](settings.html#std:setting-CONCURRENT_REQUESTS_PER_IP) 选项。它会产生类似的效果，但有一些重要的区别：

*   因为下载延迟很小，偶尔会有突发的请求；
*   通常，非200（错误）响应的返回速度比常规响应快，因此，只要有一个较小的下载延迟和硬并发限制，当服务器开始返回错误时，爬虫程序将更快地向服务器发送请求。但这与爬虫应该做的相反——如果出现错误，放慢速度更有意义：这些错误可能是由高请求率引起的。

AutoThrottle 没有这些问题。

## 节流算法

AutoThrottle 算法根据以下规则调整下载延迟：

1.  Spider 总是以下载延迟开始 [`AUTOTHROTTLE_START_DELAY`](#std:setting-AUTOTHROTTLE_START_DELAY) ；
2.  当收到响应时，目标下载延迟计算为 `latency / N` 在哪里？ `latency` 是响应的延迟，并且 `N` 是 [`AUTOTHROTTLE_TARGET_CONCURRENCY`](#std:setting-AUTOTHROTTLE_TARGET_CONCURRENCY) .
3.  下一个请求的下载延迟设置为上一个下载延迟和目标下载延迟的平均值；
4.  不允许非200响应的延迟减少延迟；
5.  下载延迟不能小于 [`DOWNLOAD_DELAY`](settings.html#std:setting-DOWNLOAD_DELAY) 或大于 [`AUTOTHROTTLE_MAX_DELAY`](#std:setting-AUTOTHROTTLE_MAX_DELAY)

注解

autothrottle扩展支持并发和延迟的标准碎片设置。这意味着它将尊重 [`CONCURRENT_REQUESTS_PER_DOMAIN`](settings.html#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN) 和 [`CONCURRENT_REQUESTS_PER_IP`](settings.html#std:setting-CONCURRENT_REQUESTS_PER_IP) 选项，并且从不将下载延迟设置为低于 [`DOWNLOAD_DELAY`](settings.html#std:setting-DOWNLOAD_DELAY) .

在scrappy中，下载延迟是以建立TCP连接和接收HTTP头之间所经过的时间来度量的。

注意，在一个合作的多任务环境中，这些延迟很难精确测量，因为scrapy可能正忙于处理spider回调，例如，无法参加下载。然而，这些延迟仍然应该对Scrapy（最终是服务器）有多忙给出一个合理的估计，并且这个扩展是在这个前提下构建的。

## 设置

用于控制 AutoThrottle 扩展的设置为：

*   [`AUTOTHROTTLE_ENABLED`](#std:setting-AUTOTHROTTLE_ENABLED)
*   [`AUTOTHROTTLE_START_DELAY`](#std:setting-AUTOTHROTTLE_START_DELAY)
*   [`AUTOTHROTTLE_MAX_DELAY`](#std:setting-AUTOTHROTTLE_MAX_DELAY)
*   [`AUTOTHROTTLE_TARGET_CONCURRENCY`](#std:setting-AUTOTHROTTLE_TARGET_CONCURRENCY)
*   [`AUTOTHROTTLE_DEBUG`](#std:setting-AUTOTHROTTLE_DEBUG)
*   [`CONCURRENT_REQUESTS_PER_DOMAIN`](settings.html#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN)
*   [`CONCURRENT_REQUESTS_PER_IP`](settings.html#std:setting-CONCURRENT_REQUESTS_PER_IP)
*   [`DOWNLOAD_DELAY`](settings.html#std:setting-DOWNLOAD_DELAY)

有关详细信息，请参阅 [它是如何工作的](#autothrottle-algorithm) .

### AUTOTHROTTLE_ENABLED

违约： `False`

启用AutoThrottle 扩展。

### AUTOTHROTTLE_START_DELAY

违约： `5.0`

初始下载延迟（秒）。

### AUTOTHROTTLE_MAX_DELAY

违约： `60.0`

在高延迟情况下设置的最大下载延迟（秒）。

### AUTOTHROTTLE_TARGET_CONCURRENCY

1.1 新版功能.

违约： `1.0`

Scrapy的平均请求数应与远程网站并行发送。

默认情况下，autothrottle会调整延迟以向每个远程网站发送单个并发请求。将此选项设置为更高的值（例如 `2.0` ）以增加远程服务器的吞吐量和负载。下层 `AUTOTHROTTLE_TARGET_CONCURRENCY` 价值（例如） `0.5` ）让爬虫人更加保守和礼貌。

注意 [`CONCURRENT_REQUESTS_PER_DOMAIN`](settings.html#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN) 和 [`CONCURRENT_REQUESTS_PER_IP`](settings.html#std:setting-CONCURRENT_REQUESTS_PER_IP) 启用 AutoThrottle 扩展功能时，仍会遵循选项。这意味着如果 `AUTOTHROTTLE_TARGET_CONCURRENCY` 设置为大于的值 [`CONCURRENT_REQUESTS_PER_DOMAIN`](settings.html#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN) 或 [`CONCURRENT_REQUESTS_PER_IP`](settings.html#std:setting-CONCURRENT_REQUESTS_PER_IP) ，爬虫程序将无法达到此数量的并发请求。

在每个给定的时间点上，scrapy可以发送的并发请求多于或少于 `AUTOTHROTTLE_TARGET_CONCURRENCY` ；这是爬虫尝试接近的建议值，而不是硬限制。

### AUTOTHROTTLE_DEBUG

违约： `False`

启用 AutoThrottle 调试模式，该模式将显示收到的每个响应的统计信息，以便您可以看到如何实时调整节流参数。