# Feed 导出

> 译者：[OSGeo 中国](https://www.osgeo.cn/)

0.10 新版功能.

在实现scraper时，最经常需要的功能之一是能够正确地存储被抓取的数据，这通常意味着用被抓取的数据（通常称为“导出提要”）生成一个“导出文件”，供其他系统使用。

Scrapy随提要导出一起提供了开箱即用的功能，它允许您使用多个序列化格式和存储后端生成带有已擦除项的提要。

## 序列化格式

为了序列化抓取的数据，提要导出使用 [Item exporters](exporters.html#topics-exporters) . 开箱即用支持这些格式：

> *   [JSON](#topics-feed-format-json)
> *   [杰森线](#topics-feed-format-jsonlines)
> *   [CSV](#topics-feed-format-csv)
> *   [XML](#topics-feed-format-xml)

但是您也可以通过 [`FEED_EXPORTERS`](#std:setting-FEED_EXPORTERS) 设置。

### JSON

> *   [`FEED_FORMAT`](#std:setting-FEED_FORMAT): `json`
> *   出口商： [`JsonItemExporter`](exporters.html#scrapy.exporters.JsonItemExporter "scrapy.exporters.JsonItemExporter")
> *   见 [this warning](exporters.html#json-with-large-data) 如果您使用的是大型提要的JSON。

### 杰森线

> *   [`FEED_FORMAT`](#std:setting-FEED_FORMAT): `jsonlines`
> *   出口商： [`JsonLinesItemExporter`](exporters.html#scrapy.exporters.JsonLinesItemExporter "scrapy.exporters.JsonLinesItemExporter")

### CSV

> *   [`FEED_FORMAT`](#std:setting-FEED_FORMAT): `csv`
> *   出口商： [`CsvItemExporter`](exporters.html#scrapy.exporters.CsvItemExporter "scrapy.exporters.CsvItemExporter")
> *   指定要导出的列及其顺序的步骤使用 [`FEED_EXPORT_FIELDS`](#std:setting-FEED_EXPORT_FIELDS) . 其他feed导出器也可以使用此选项，但对于csv很重要，因为与许多其他导出格式不同，csv使用固定头。

### XML

> *   [`FEED_FORMAT`](#std:setting-FEED_FORMAT): `xml`
> *   出口商： [`XmlItemExporter`](exporters.html#scrapy.exporters.XmlItemExporter "scrapy.exporters.XmlItemExporter")

### 泡菜

> *   [`FEED_FORMAT`](#std:setting-FEED_FORMAT): `pickle`
> *   出口商： [`PickleItemExporter`](exporters.html#scrapy.exporters.PickleItemExporter "scrapy.exporters.PickleItemExporter")

### 元帅

> *   [`FEED_FORMAT`](#std:setting-FEED_FORMAT): `marshal`
> *   出口商： `MarshalItemExporter`

## 储藏室

当使用feed导出时，您定义使用uri（通过 [`FEED_URI`](#std:setting-FEED_URI) 设置）。提要导出支持由URI方案定义的多个存储后端类型。

开箱支持的存储后端包括：

> *   [本地文件系统](#topics-feed-storage-fs)
> *   [FTP](#topics-feed-storage-ftp)
> *   [S3](#topics-feed-storage-s3) （需要botocore_u或boto_u）
> *   [标准输出](#topics-feed-storage-stdout)

如果所需的外部库不可用，则某些存储后端可能不可用。例如，只有在安装了botocore_u或boto_u库的情况下，S3后端才可用（scrapy仅在python 2上支持boto_u）。

## 存储URI参数

存储URI还可以包含在创建源时被替换的参数。这些参数是：

> *   `%(time)s` -在创建源时被时间戳替换
> *   `%(name)s` -替换为 Spider 名称

任何其他命名参数都将被同名的spider属性替换。例如， `%(site_id)s` 将被替换为 `spider.site_id` 属性为正在创建源的时刻。

下面举例说明：

> *   使用每个spider一个目录存储在ftp中：
>     *   `ftp://user:password@ftp.example.com/scraping/feeds/%(name)s/%(time)s.json`
> *   使用每个spider一个目录存储在S3中：
>     *   `s3://mybucket/scraping/feeds/%(name)s/%(time)s.json`

## 存储后端

### 本地文件系统

源存储在本地文件系统中。

> *   URI方案： `file`
> *   示例性URI： `file:///tmp/export.csv`
> *   所需外部库：无

请注意，对于本地文件系统存储（仅限），如果您指定类似 `/tmp/export.csv` . 不过，这只在UNIX系统上工作。

### FTP

这些提要存储在FTP服务器中。

> *   URI方案： `ftp`
> *   示例性URI： `ftp://user:pass@ftp.example.com/path/to/export.csv`
> *   所需外部库：无

### S3

源存储在 [Amazon S3](https://aws.amazon.com/s3/) .

> *   URI方案： `s3`
> *   URI示例：
>     *   `s3://mybucket/path/to/export.csv`
>     *   `s3://aws_key:aws_secret@mybucket/path/to/export.csv`
> *   所需的外部库： [botocore](https://github.com/boto/botocore) （python 2和python 3）或 [boto](https://github.com/boto/boto) （仅Python 2）

AWS凭证可以作为用户/密码在URI中传递，也可以通过以下设置传递：

> *   [`AWS_ACCESS_KEY_ID`](settings.html#std:setting-AWS_ACCESS_KEY_ID)
> *   [`AWS_SECRET_ACCESS_KEY`](settings.html#std:setting-AWS_SECRET_ACCESS_KEY)

还可以使用此设置为导出的源定义自定义ACL：

> *   [`FEED_STORAGE_S3_ACL`](#std:setting-FEED_STORAGE_S3_ACL)

### 标准输出

进料被写入废料处理的标准输出。

> *   URI方案： `stdout`
> *   示例性URI： `stdout:`
> *   所需外部库：无

## 设置

以下是用于配置源导出的设置：

> *   [`FEED_URI`](#std:setting-FEED_URI) （强制性）
> *   [`FEED_FORMAT`](#std:setting-FEED_FORMAT)
> *   [`FEED_STORAGES`](#std:setting-FEED_STORAGES)
> *   [`FEED_STORAGE_S3_ACL`](#std:setting-FEED_STORAGE_S3_ACL)
> *   [`FEED_EXPORTERS`](#std:setting-FEED_EXPORTERS)
> *   [`FEED_STORE_EMPTY`](#std:setting-FEED_STORE_EMPTY)
> *   [`FEED_EXPORT_ENCODING`](#std:setting-FEED_EXPORT_ENCODING)
> *   [`FEED_EXPORT_FIELDS`](#std:setting-FEED_EXPORT_FIELDS)
> *   [`FEED_EXPORT_INDENT`](#std:setting-FEED_EXPORT_INDENT)

### FEED_URI

违约： `None`

导出源的URI。见 [存储后端](#topics-feed-storage-backends) 用于支持的URI方案。

启用源导出需要此设置。

### FEED_FORMAT

要用于源的序列化格式。见 [序列化格式](#topics-feed-format) 对于可能的值。

### FEED_EXPORT_ENCODING

违约： `None`

要用于源的编码。

如果未设置或设置为 `None` （默认）它对除JSON输出之外的所有内容都使用UTF-8，JSON输出使用安全的数字编码。（ `\uXXXX` 序列）出于历史原因。

使用 `utf-8` 如果您也想要为JSON使用UTF-8。

### FEED_EXPORT_FIELDS

违约： `None`

要导出的字段列表，可选。例子： `FEED_EXPORT_FIELDS = ["foo", "bar", "baz"]` .

使用feed_export_fields选项定义要导出的字段及其顺序。

当feed-export-fields为空或无时（默认），scrappy使用dicts或 [`Item`](items.html#scrapy.item.Item "scrapy.item.Item") Spider 正在屈服的亚纲。

如果导出器需要一组固定的字段（这是 [CSV](#topics-feed-format-csv) export format）和feed_export_字段为空或无，然后scrapy尝试从导出的数据中推断字段名-当前它使用第一个项目中的字段名。

### FEED_EXPORT_INDENT

违约： `0`

用于在每个级别上缩进输出的空间量。如果 `FEED_EXPORT_INDENT` 是非负整数，则数组元素和对象成员将以该缩进级别进行漂亮打印。缩进量 `0` （默认值）或负数，将把每个项目放到一个新行上。 `None` 选择最紧凑的表示形式。

当前仅由执行 [`JsonItemExporter`](exporters.html#scrapy.exporters.JsonItemExporter "scrapy.exporters.JsonItemExporter") 和 [`XmlItemExporter`](exporters.html#scrapy.exporters.XmlItemExporter "scrapy.exporters.XmlItemExporter") ，即当您要导出到 `.json` 或 `.xml` .

### FEED_STORE_EMPTY

违约： `False`

是否导出空源（即没有项目的源）。

### FEED_STORAGES

违约： `{{}}`

包含项目支持的其他提要存储后端的dict。键是URI方案，值是指向存储类的路径。

### FEED_STORAGE_S3_ACL

违约： `''` （空字符串）

包含项目导出到AmazonS3的源的自定义ACL的字符串。

有关可用值的完整列表，请访问 [Canned ACL](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl) 亚马逊S3文档部分。

### FEED_STORAGES_BASE

违约：：

```py
{
    '': 'scrapy.extensions.feedexport.FileFeedStorage',
    'file': 'scrapy.extensions.feedexport.FileFeedStorage',
    'stdout': 'scrapy.extensions.feedexport.StdoutFeedStorage',
    's3': 'scrapy.extensions.feedexport.S3FeedStorage',
    'ftp': 'scrapy.extensions.feedexport.FTPFeedStorage',
}

```

包含由Scrapy支持的内置提要存储后端的dict。您可以通过分配 `None` 到他们的URI方案 [`FEED_STORAGES`](#std:setting-FEED_STORAGES) . 例如，要禁用内置FTP存储后端（不替换），请将其放入 `settings.py` ：：

```py
FEED_STORAGES = {
    'ftp': None,
}

```

### FEED_EXPORTERS

违约： `{{}}`

包含项目支持的其他导出器的dict。键是序列化格式，值是指向 [Item exporter](exporters.html#topics-exporters) 类。

### FEED_EXPORTERS_BASE

违约：：

```py
{
    'json': 'scrapy.exporters.JsonItemExporter',
    'jsonlines': 'scrapy.exporters.JsonLinesItemExporter',
    'jl': 'scrapy.exporters.JsonLinesItemExporter',
    'csv': 'scrapy.exporters.CsvItemExporter',
    'xml': 'scrapy.exporters.XmlItemExporter',
    'marshal': 'scrapy.exporters.MarshalItemExporter',
    'pickle': 'scrapy.exporters.PickleItemExporter',
}

```

包含由Scrapy支持的内置饲料导出器的dict。您可以通过分配 `None` 到其序列化格式 [`FEED_EXPORTERS`](#std:setting-FEED_EXPORTERS) . 例如，要禁用内置的csv导出器（不替换），请将其放入 `settings.py` ：：

```py
FEED_EXPORTERS = {
    'csv': None,
}

```