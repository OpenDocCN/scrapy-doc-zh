# 安装指南

> 译者：[OSGeo 中国](https://www.osgeo.cn/)

## 安装 Scrapy

scrapy在cpython（默认的Python实现）和pypypy（从pypy 5.9开始）下运行于python 2.7和python 3.4或更高版本。

如果你在用 [Anaconda](https://docs.anaconda.com/anaconda/) 或 [Miniconda](https://conda.io/docs/user-guide/install/index.html) ，您可以从 [conda-forge](https://conda-forge.org/) 频道，它有最新的Linux、Windows和OS X软件包。

使用安装 Scrapy `conda` 运行：

```py
conda install -c conda-forge scrapy

```

或者，如果您已经熟悉了python包的安装，那么可以从pypi安装scrappy及其依赖项，方法是：

```py
pip install Scrapy

```

请注意，有时这可能需要根据操作系统解决一些零碎依赖项的编译问题，因此请确保检查 [平台特定安装说明](#intro-install-platform-notes) .

我们强烈建议您在 [a dedicated virtualenv](#intro-using-virtualenv) ，以避免与系统包冲突。

有关更详细和平台特定的说明以及故障排除信息，请阅读。

### 很好知道的事情

scrappy是用纯python编写的，它依赖于几个关键的python包（以及其他包）：

*   [lxml](http://lxml.de/) 一个高效的XML和HTML解析器
*   [parsel](https://pypi.python.org/pypi/parsel) ，一个写在lxml上面的html/xml数据提取库，
*   [w3lib](https://pypi.python.org/pypi/w3lib) ，用于处理URL和网页编码的多用途帮助程序
*   [twisted](https://twistedmatrix.com/) 异步网络框架
*   [cryptography](https://cryptography.io/) 和 [pyOpenSSL](https://pypi.python.org/pypi/pyOpenSSL) ，处理各种网络级安全需求

Scrapy测试的最小版本是：

*   扭曲14
*   LXML 3.4
*   PyopSnSL 0.14

Scrapy可以与这些软件包的旧版本一起工作，但不能保证它会继续工作，因为它没有针对它们进行测试。

其中一些软件包本身依赖于非python软件包，这些软件包可能需要依赖于您的平台的其他安装步骤。请检查 [platform-specific guides below](#intro-install-platform-notes) .

如果与这些依赖项相关的任何问题，请参阅它们各自的安装说明：

*   [lxml installation](http://lxml.de/installation.html)
*   [cryptography installation](https://cryptography.io/en/latest/installation/)

### 使用虚拟环境（推荐）

tl；dr：我们建议在所有平台上的虚拟环境中安装scrapy。

python包可以在全局（也就是系统范围）或用户空间中安装。我们不建议在系统范围内安装Scrapy。

相反，我们建议您在所谓的“虚拟环境”中安装Scrapy。（ [virtualenv](https://virtualenv.pypa.io) ）virtualenvs允许您不与已经安装的python系统包冲突（这可能会破坏某些系统工具和脚本），并且仍然可以使用 `pip` （没有） `sudo` 诸如此类。

要开始使用虚拟环境，请参见 [virtualenv installation instructions](https://virtualenv.pypa.io/en/stable/installation/) . 要在全球范围内安装它（让它在全球范围内安装实际上有助于实现这一点），应该运行：

```py
$ [sudo] pip install virtualenv

```

检查这个 [user guide](https://virtualenv.pypa.io/en/stable/userguide/) 关于如何创建virtualenv。

注解

如果您使用Linux或OS X， [virtualenvwrapper](https://virtualenvwrapper.readthedocs.io/en/latest/install.html) 是创建virtualenv的便利工具。

创建virtualenv后，可以在其中安装scrapy `pip` 就像其他的python包一样。（见 [platform-specific guides](#intro-install-platform-notes) 下面是您可能需要预先安装的非python依赖项）。

默认情况下，可以创建python virtualenv来使用python 2或python 3。

*   如果要使用python 3安装scrapy，请在python 3 virtualenv中安装scrapy。
*   如果您想用python 2安装scrapy，请在python 2 virtualenv中安装scrapy。

## 平台特定安装说明

### Windows

虽然可以使用pip在Windows上安装scrapy，但我们建议您安装 [Anaconda](https://docs.anaconda.com/anaconda/) 或 [Miniconda](https://conda.io/docs/user-guide/install/index.html) 并使用来自 [conda-forge](https://conda-forge.org/) 这样可以避免大多数安装问题。

安装后 [Anaconda](https://docs.anaconda.com/anaconda/) 或 [Miniconda](https://conda.io/docs/user-guide/install/index.html) ，安装 Scrapy ：

```py
conda install -c conda-forge scrapy

```

### Ubuntu 14.04或以上

Scrapy目前已经用LXML、Twisted和PyOpenSSL的最新版本进行了测试，并且与最新的Ubuntu发行版兼容。但是它也应该支持Ubuntu的旧版本，比如Ubuntu14.04，尽管存在与TLS连接相关的潜在问题。

**Don't** 使用 `python-scrapy` Ubuntu提供的软件包，它们通常太旧，速度太慢，赶不上最新的垃圾。

要在Ubuntu（或基于Ubuntu的）系统上安装Scrapy，需要安装以下依赖项：

```py
sudo apt-get install python-dev python-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev

```

*   `python-dev`, `zlib1g-dev`, `libxml2-dev` and `libxslt1-dev` are required for `lxml`
*   `libssl-dev` and `libffi-dev` are required for `cryptography`

如果要在python 3上安装scrapy，还需要python 3开发头：

```py
sudo apt-get install python3 python3-dev

```

里面 [virtualenv](#intro-using-virtualenv) ，您可以安装Scrapy `pip` 之后：：

```py
pip install scrapy

```

注解

相同的非python依赖项可用于在debian jessie（8.0）及更高版本中安装scrapy。

### Mac OS X

构建Scrapy的依赖项需要有一个C编译器和开发头。在OS X上，这通常由苹果的Xcode开发工具提供。要安装xcode命令行工具，请打开终端窗口并运行：

```py
xcode-select --install

```

有一个 [known issue](https://github.com/pypa/pip/issues/2468) 防止 `pip` 更新系统包。必须解决此问题才能成功安装Scrapy及其依赖项。以下是一些建议的解决方案：

*   _（推荐）_ **Don't** 使用系统python，安装一个新的、更新的版本，它不会与系统的其他部分冲突。以下是如何使用 [homebrew](https://brew.sh/) 包管理器：

    *   安装 [homebrew](https://brew.sh/) 遵循https://brew.sh中的说明/

    *   更新你的 `PATH` 变量，说明应在系统包之前使用自制包（更改 `.bashrc` 到 `.zshrc` 如果你在使用 [zsh](https://www.zsh.org/) 作为默认Shell）：：

        ```py
        echo "export PATH=/usr/local/bin:/usr/local/sbin:$PATH" &gt;&gt; ~/.bashrc

        ```

    *   再装填 `.bashrc` 为确保变更发生：

        ```py
        source ~/.bashrc

        ```

    *   安装python:：

        ```py
        brew install python

        ```

    *   最新版本的python `pip` 与它们捆绑在一起，这样您就不需要单独安装。如果不是这样，请升级python:：

        ```py
        brew update; brew upgrade python

        ```

*   [*](#id1)（可选）*在隔离的python环境中安装scrapy。

    此方法是解决上述OS X问题的一种方法，但它是管理依赖性的总体良好实践，可以补充第一种方法。

    [virtualenv](https://virtualenv.pypa.io) 是一个可以用来在Python中创建虚拟环境的工具。我们建议阅读http://docs.python-guide.org/en/latest/dev/virtualenvs/这样的教程开始学习。

在任何这些解决方法之后，您都应该能够安装scrapy:：

```py
pip install Scrapy

```

### PyPy

我们建议使用最新的Pypy版本。测试版本为5.9.0。对于pypy3，只测试了Linux安装。

大多数依赖于废品的人现在都有cpython的二进制轮子，而不是pypy的。这意味着这些依赖项将在安装期间构建。在OSX上，您可能会面临构建加密依赖关系的问题，本文描述了该问题的解决方案。 [here](https://github.com/pyca/cryptography/issues/2692#issuecomment-272773481) ，就是 `brew install openssl` 然后导出此命令推荐的标志（仅在安装scrapy时需要）。在Linux上安装除了安装构建依赖项之外没有任何特殊问题。未测试在Windows上安装带有Pypy的Scrapy。

您可以通过运行来检查Scrapy是否安装正确。 `scrapy bench` . 如果此命令给出错误，例如 `TypeError: ... got 2 unexpected keyword arguments` ，这意味着安装工具无法获取一个Pypy特定的依赖项。要解决此问题，请运行 `pip install 'PyPyDispatcher&gt;=2.1.0'` .

## 故障排除

### attributeError:“module”对象没有属性“op u no u tlsv1 u 1”

安装或升级scrappy、twisted或pyopenssl之后，可能会得到以下跟踪的异常：

```py
[…]
  File "[…]/site-packages/twisted/protocols/tls.py", line 63, in <module>
    from twisted.internet._sslverify import _setAcceptableProtocols
  File "[…]/site-packages/twisted/internet/_sslverify.py", line 38, in <module>
    TLSVersion.TLSv1_1: SSL.OP_NO_TLSv1_1,
AttributeError: 'module' object has no attribute 'OP_NO_TLSv1_1'

```

您得到这个异常的原因是您的系统或虚拟环境有一个您的Twisted版本不支持的pyopenssl版本。

要安装您的Twisted版本支持的pyopenssl版本，请使用 `tls` 额外选项：

```py
pip install twisted[tls]

```

有关详细信息，请参阅 [Issue #2473](https://github.com/scrapy/scrapy/issues/2473) .